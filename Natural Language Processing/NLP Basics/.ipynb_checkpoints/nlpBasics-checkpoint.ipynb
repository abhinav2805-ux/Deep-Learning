{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdbea676-6e6f-47e3-982d-c9dadd21fee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\gupta\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc394a4f-97ba-4cc1-b9fd-0ad80b3cbb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e670d8e-d438-4643-bd19-36f9bba0095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"Hello Geeks. We're Hoping you guyz are doing great.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b7eb787-99d3-4707-80ec-4d16e125175c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Geeks. We're Hoping you guyz are doing great.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fb9d7bc-dfce-4c4c-8b48-54a0db317bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Geeks', \" We're Hoping you guyz are doing great\", '']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7a65039-c696-4f51-9fd4-96083757ec96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'Geeks.', \"We're\", 'Hoping', 'you', 'guyz', 'are', 'doing', 'great.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e95520c1-0b50-47e4-bec4-27246f1a4d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7c880dc-2bba-4ac6-9bca-bb52638709e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize , sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16a4be71-a8b1-42ed-a800-3e4b16ac1f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Geeks',\n",
       " '.',\n",
       " 'We',\n",
       " \"'re\",\n",
       " 'Hoping',\n",
       " 'you',\n",
       " 'guyz',\n",
       " 'are',\n",
       " 'doing',\n",
       " 'great',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "670d2a56-7dae-4cd6-a5fb-837be151f3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Geeks.', \"We're Hoping you guyz are doing great.\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f25f978c-d71e-4d34-b6a8-b7cf48115302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Geeks\n",
      "We\n",
      "'re\n",
      "Hoping\n",
      "you\n",
      "guyz\n",
      "are\n",
      "doing\n",
      "great\n"
     ]
    }
   ],
   "source": [
    "for word in word_tokenize(txt):\n",
    "    if(word!='.'):\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3407c914-8667-4bf7-9fc8-3d726eb90c88",
   "metadata": {},
   "source": [
    "## stemming & Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77d0e47b-1fa4-467c-a881-c453ec9b8a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06ca5d03-147a-4f61-9a04-a0493b985db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer , PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b0b1a6e-e861-4588-a254-ff3e6bf9899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = PorterStemmer()\n",
    "lam = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de066ce2-7ff9-4f00-979a-0cc0461a42e9",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17f04145-ce78-4c6a-86d0-2fdf679a6eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change\n",
      "change\n",
      "changer\n",
      "changed\n"
     ]
    }
   ],
   "source": [
    "print(lam.lemmatize('change'))\n",
    "print(lam.lemmatize('changes'))\n",
    "print(lam.lemmatize('changer'))\n",
    "print(lam.lemmatize('changed'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d1996d-b5ab-42ed-938c-9b423d59ea85",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db78c3fb-f832-43c3-9269-f1988e889bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chang\n",
      "chang\n",
      "chang\n"
     ]
    }
   ],
   "source": [
    "print(stem.stem('change'))\n",
    "print(stem.stem('changed'))\n",
    "print(stem.stem('changes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51b8d9e-0bff-4ccd-9657-16a0d853381d",
   "metadata": {},
   "source": [
    "# StopWords Removal from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1afb9486-c6f7-4250-a4a0-f5d5d809d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'This is not a good time to talk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71e32aec-8739-424e-8333-fe6506faae9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is not a good time to talk'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bb0dd4b-3b34-4541-81c4-e152c6ec5264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de09c894-6cb3-4520-902d-0382779b4cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb34e371-8f32-4a9b-bdae-37376657c655",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3f6d478-237f-4625-9264-f19e8994c0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea82d27a-307e-438b-8fb8-b581b22fc8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1cb8b95-cae8-4bd0-a45c-f261923aea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = word_tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ffa2b96-d5c6-4c9d-b82f-3fcdd17d71e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'not', 'a', 'good', 'time', 'to', 'talk']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "785c6186-fc2b-4073-a6be-5b7df9023861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "time\n",
      "talk\n"
     ]
    }
   ],
   "source": [
    "for word in txt:\n",
    "    if((word.lower() not in stopword) and (len(word)>=2)):\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb95f59-1c37-4f19-9fd5-0404c37b402c",
   "metadata": {},
   "source": [
    "# Corpus and Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bddded22-c1d6-4496-837c-e34e65917d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"India is a country in South Asia. It is the seventh-largest country by land area, the second-most populous country, and the most populous democracy in the world.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ec637b5-edeb-440d-8bb6-d2420ec0e393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'India is a country in South Asia. It is the seventh-largest country by land area, the second-most populous country, and the most populous democracy in the world.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b09ea817-c7ab-47ee-8484-df8ac83c0e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India',\n",
       " 'is',\n",
       " 'a',\n",
       " 'country',\n",
       " 'in',\n",
       " 'South',\n",
       " 'Asia',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'the',\n",
       " 'seventh-largest',\n",
       " 'country',\n",
       " 'by',\n",
       " 'land',\n",
       " 'area',\n",
       " ',',\n",
       " 'the',\n",
       " 'second-most',\n",
       " 'populous',\n",
       " 'country',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'most',\n",
       " 'populous',\n",
       " 'democracy',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " '.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3131a21-c114-41f5-9559-2aabcd05858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "\n",
    "for word in word_tokenize(corpus):\n",
    "    if(word.lower() not in stopword and (len(word)>=2)):\n",
    "        words.append(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31846ac3-c692-4d5f-a38e-ec1cb2c61597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['india',\n",
       " 'country',\n",
       " 'south',\n",
       " 'asia',\n",
       " 'seventh-largest',\n",
       " 'country',\n",
       " 'land',\n",
       " 'area',\n",
       " 'second-most',\n",
       " 'populous',\n",
       " 'country',\n",
       " 'populous',\n",
       " 'democracy',\n",
       " 'world']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5057ae03-24e2-4b8b-a478-e5cfd1af5fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(words))\n",
    "print(len(set(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3a3b613-f408-47d3-a7fc-abc4fd000552",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a307209-b91a-45df-933c-130d231cb4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['india',\n",
       " 'second-most',\n",
       " 'area',\n",
       " 'world',\n",
       " 'country',\n",
       " 'land',\n",
       " 'seventh-largest',\n",
       " 'democracy',\n",
       " 'south',\n",
       " 'populous',\n",
       " 'asia']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d61447c3-78d7-452a-8b2b-a9563f7da1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India is a country in South Asia.\n",
      "It is the seventh-largest country by land area, the second-most populous country, and the most populous democracy in the world.\n"
     ]
    }
   ],
   "source": [
    "for sent in sent_tokenize(corpus):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b82ffe32-21da-4bea-aa9c-da97c8e205fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a car'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"This is a car\"\n",
    "\n",
    "# this = 1\n",
    "# is = 2\n",
    "# a = 3\n",
    "# car = 4\n",
    "\n",
    "# 1 2 3 4 (this is a car)\n",
    "# 2 1 3 4 (iis this a car ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd1b41e-b4d1-4546-918e-635f6e8d2bc5",
   "metadata": {},
   "source": [
    "# keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a50bb15-1caf-4881-8325-90c7daee6833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\gupta\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a84f40eb-4b5d-4396-9285-467b30c71151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is': 1, 'coffee': 2, 'hot': 3, 'water': 4, 'cold': 5}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tok = Tokenizer()\n",
    "\n",
    "# Define a sample corpus\n",
    "corpus = ['coffee is hot', 'water is cold']\n",
    "\n",
    "# Fit the tokenizer on the corpus\n",
    "tok.fit_on_texts(corpus)\n",
    "\n",
    "# View the word-to-index mapping\n",
    "tok.word_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92d8beed-1e49-447a-8505-e8648584189a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 1, 3], [2, 1, 5]]\n"
     ]
    }
   ],
   "source": [
    "# Convert new texts to sequences\n",
    "sequences = tok.texts_to_sequences(['water is hot', 'black coffee is cold'])\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3d3d292-89c6-4402-9cbb-40474856ca6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, 'is': 2, 'coffee': 3, 'hot': 4, 'water': 5, 'cold': 6}\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer with OOV support\n",
    "tok = Tokenizer(oov_token='<OOV>')\n",
    "\n",
    "# Fit on the corpus\n",
    "tok.fit_on_texts(corpus)\n",
    "\n",
    "# View updated word index\n",
    "print(tok.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "331fe490-5ea9-4f1b-ad0f-93f2a313ffc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 2, 4], [1, 3, 2, 6]]\n"
     ]
    }
   ],
   "source": [
    "sequences = tok.texts_to_sequences(['water is hot', 'black coffee is cold'])\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1aeb6e92-d564-4093-bad8-e3401e798992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is': 1, 'coffee': 2, 'hot': 3, 'water': 4, 'cold': 5}\n"
     ]
    }
   ],
   "source": [
    "# Limit vocabulary to the top 5 most frequent words\n",
    "tok = Tokenizer(num_words=6)\n",
    "tok.fit_on_texts(corpus)\n",
    "\n",
    "print(tok.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ac43e60-33cf-4027-b7e8-67ca1b8be5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 1, 3], [2, 1, 5]]\n"
     ]
    }
   ],
   "source": [
    "sequences = tok.texts_to_sequences(['water is hot', 'black coffee is cold'])\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5b136-435a-4ff5-a86a-99ccc25964f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
