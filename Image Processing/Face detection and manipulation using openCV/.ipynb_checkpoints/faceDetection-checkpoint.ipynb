{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb4a5de3-58d1-4a77-a0ae-26906244edc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085d8aa3-2d0b-444b-906e-ba796a250098",
   "metadata": {},
   "source": [
    "# Haar Cascade Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4a10e9-407d-4e20-bb7d-642dfad9ea2a",
   "metadata": {},
   "source": [
    "this is used to detect the face (This file contains all the features of the face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d536ea-35f4-4436-a50e-a54fe9dee252",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cam = cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    _, img = cam.read()\n",
    "    img = cv.flip(img,1)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        faces = classifier.detectMultiScale(img, 1.1, 5) # return the coordinates of the face\n",
    "            # parameter (1.1) -> no of frames per second we send if the values is more than detect less face and if value is less then detect more faces\n",
    "            # parameter (5) is a confidence parameter (no of neighbour faces)\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv.rectangle(img, (x,y),(x+w,y+h) , (0,180,0), 3)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    cv.imshow('Frame'  , img )\n",
    "    \n",
    "    if cv.waitKey(1) == 27:\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4751c43-4176-42c0-a9bf-fb05a07567cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43f4c52-3e10-4ee5-9743-833fd0f22692",
   "metadata": {},
   "source": [
    "# Face Crop on Live WebCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "458d0b6f-569d-442c-977c-9c228c6417f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "classifier = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cam = cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, img = cam.read()\n",
    "    img = cv.flip(img, 1)\n",
    "\n",
    "    faces = classifier.detectMultiScale(img, 1.1, 5)\n",
    "\n",
    "    face = None  # Initialize face variable\n",
    "    \n",
    "    if len(faces) >= 1:\n",
    "        f = max(faces, key=lambda x: x[2] * x[3])  # Find the face with the largest area\n",
    "\n",
    "        x, y, w, h = f\n",
    "        cv.rectangle(img, (x, y), (x + w, y + h), (0, 180, 0), 2)\n",
    "        face = img[y:y+h, x:x+w]\n",
    "        face = cv.resize(face, (256, 256))\n",
    "\n",
    "    cv.imshow('Frame', img)\n",
    "    \n",
    "    if face is not None:  # Only show 'Face' window if a face is detected\n",
    "        cv.imshow('Face', face)\n",
    "\n",
    "    if cv.waitKey(1) == 27:  # Press 'Esc' key to exit\n",
    "        cam.release()\n",
    "        cv.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ead889-1546-411f-893b-38bf1a7fcf95",
   "metadata": {},
   "source": [
    "# Realtime Face Blur on Live WebCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3dde0c-e6a3-4447-8a88-859f7b822ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cam = cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    _, img = cam.read()\n",
    "    img = cv.flip(img,1)\n",
    "    \n",
    "    faces = classifier.detectMultiScale(img, 1.1, 5)\n",
    "    \n",
    "    for f in faces:\n",
    "        if f[-1] == max(faces[:,-1]):\n",
    "            break\n",
    "\n",
    "    if (len(faces) >= 1):\n",
    "        x = f[0] \n",
    "        y = f[1] \n",
    "        w = f[2]\n",
    "        h = f[3]\n",
    "\n",
    "#         cv.rectangle(img, (x,y),(x+w,y+h) , (0,180,0), 2)   \n",
    "\n",
    "        face = img[y:y+h, x:x+w]                 # Getting the Face Area from Video Feed\n",
    "        face = cv.blur(face, (32,32))            # Applying Blur on the Face\n",
    "        img[y:y+h, x:x+w] = face                 # Apply Blured Face on Video Feed\n",
    "        \n",
    "\n",
    "    cv.imshow('Frame'  , img )\n",
    "    cv.imshow('Face'   , face)\n",
    "    \n",
    "    if cv.waitKey(1) == 27:\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2c673b-8e09-45f1-85cd-68f3229ab013",
   "metadata": {},
   "source": [
    "# Realtime Face Black on Live WebCam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ca6f4b-e9d7-43a4-bbbf-d81bc255696a",
   "metadata": {},
   "source": [
    "## Creating Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "194b2558-83de-48b7-be66-40d5c7f77a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "classifier = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cam = cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    _, img = cam.read()\n",
    "    img = cv.flip(img,1)\n",
    "    \n",
    "    faces = classifier.detectMultiScale(img, 1.1, 5)\n",
    "    \n",
    "    for f in faces:\n",
    "        if f[-1] == max(faces[:,-1]):\n",
    "            break\n",
    "\n",
    "    x = f[0] \n",
    "    y = f[1] \n",
    "    w = f[2]\n",
    "    h = f[3]\n",
    "\n",
    "    face = img[y:y+h, x:x+w]\n",
    "    \n",
    "    black = np.zeros((face.shape), dtype = int)\n",
    "    \n",
    "    img[y:y+h, x:x+w] = black\n",
    "\n",
    "    cv.imshow('Frame'  , img )\n",
    "    cv.imshow('Face'   , face)\n",
    "    \n",
    "    if cv.waitKey(1) == 27:\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a7c62-882c-46c1-9596-f9a8757d4298",
   "metadata": {},
   "source": [
    "## Creating Circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80416fcf-7d1c-4852-91b5-05038ecce6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "classifier = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cam = cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    _, img = cam.read()\n",
    "    img = cv.flip(img,1)\n",
    "    \n",
    "    faces = classifier.detectMultiScale(img, 1.1, 5)\n",
    "    \n",
    "    for f in faces:\n",
    "        if f[-1] == max(faces[:,-1]):\n",
    "            break\n",
    "\n",
    "    x = f[0] \n",
    "    y = f[1] \n",
    "    w = f[2]\n",
    "    h = f[3]\n",
    "    \n",
    "    circle_x = x + int(w/2)\n",
    "    circle_y = y + int(h/2)\n",
    "    \n",
    "    cv.circle(img, (circle_x, circle_y), int(w/1.7), (110,180,68),-1)\n",
    "\n",
    "    cv.imshow('Frame'  , img )\n",
    "    \n",
    "    if cv.waitKey(1) == 27:\n",
    "        cam.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecfaae6-f450-4602-90f3-3b479b9fd7d9",
   "metadata": {},
   "source": [
    "# Face Extraction from an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b14a9988-47f3-439e-ab48-e38ae5b1f0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People/IMG_1.png is exported\n",
      "People/IMG_2.png is exported\n",
      "People/IMG_3.png is exported\n",
      "People/IMG_4.png is exported\n",
      "People/IMG_5.png is exported\n",
      "People/IMG_6.png is exported\n",
      "People/IMG_7.png is exported\n",
      "People/IMG_8.png is exported\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img = cv.imread('group.png')\n",
    "\n",
    "classifier = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "faces = classifier.detectMultiScale(img, 1.1, 5)\n",
    "\n",
    "\n",
    "def save(frame, folder_name): \n",
    "    name_img = len(os.listdir(folder_name)) + 1\n",
    "    name_img = folder_name + \"/IMG_\" + str(name_img) + '.png'\n",
    "    cv.imwrite(name_img, frame)\n",
    "    print(name_img ,'is exported')\n",
    "\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "\n",
    "    face = img[y:y+h, x:x+w]\n",
    "    cv.imshow('Face'   , face)\n",
    "    \n",
    "    \n",
    "    if cv.waitKey(0) == 13:         # Save the Image | 13  = Enter Key\n",
    "        save(face, 'People')\n",
    "    \n",
    "    elif cv.waitKey(0) == 127:      # Skip the Image | 127 = Delete Key\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f596676-b073-4847-b895-0caf88e552bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
