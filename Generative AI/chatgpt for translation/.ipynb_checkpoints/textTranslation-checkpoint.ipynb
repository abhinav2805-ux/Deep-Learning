{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c728423f-f1ce-4f67-8745-f27cd129b007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/fra-eng.zip\n",
      "\u001b[1m3423204/3423204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "text_file = tf.keras.utils.get_file(\n",
    "    fname='fra-eng.zip',\n",
    "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/fra-eng.zip\",\n",
    "    extract=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3733515a-ebb9-4e9e-9760-2a99f04ac1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "\n",
    "text_file = pathlib.Path(text_file).parent / 'fra.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c43391-ad90-436e-80df-0d8770579804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\.keras\\datasets\\fra.txt\n"
     ]
    }
   ],
   "source": [
    "print(text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50df5798-24bc-4150-b1cb-1b65df164394",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fra.txt') as fp:\n",
    "    text_pair = [line for line in fp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dce65a3-21ba-457a-85f0-ec9154577419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks amazing.\tCela semble merveilleux.\n",
      "\n",
      "I ate potato chips.\tJ'ai mangÃ© des chips.\n",
      "\n",
      "I don't know who that youngster is.\tJe ne sais pas qui est ce jeune homme.\n",
      "\n",
      "Take a walk every day.\tPromÃ¨ne-toi chaque jour.\n",
      "\n",
      "He stayed home from school because he wasn't feeling well.\tIl resta chez lui plutÃ´t que d'aller Ã  l'Ã©cole parce qu'il ne se sentait pas bien.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for _ in range(5):\n",
    "    print(random.choice(text_pair))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18780522-3c23-4bdf-ae5f-31233696d198",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4843a96c-279b-43dc-8476-43d79bfb891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re \n",
    "\n",
    "def normalize(line):\n",
    "    line = unicodedata.normalize(\"NFKC\" , line.strip().lower())\n",
    "    line = re.sub(r\"^([^ \\w])(?!\\s)\", r\"\\1\", line)\n",
    "    line = re.sub(r\"(\\s[^ \\w])(?!\\s)\", r\"\\1\", line)\n",
    "    line = re.sub(r\"(?!\\s)([^ \\w])$\", r\"\\1\", line)\n",
    "    line = re.sub(r\"(?!\\s)([^ \\w]\\s)\", r\"\\1\", line)\n",
    "    eng, fre = line.split(\"\\t\")\n",
    "    fre = '[start] ' + fre + ' [end]' # french\n",
    "    return eng, fre\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfe0ee0c-c4b6-461d-aa84-428163854bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fra.txt') as fp:\n",
    "    text_pairs = [normalize(line) for line in fp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c23dafa6-68ae-4a57-918b-f4441f90f700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"where's my ring?\", '[start] oã1 est ma bagueâ ? [end]')\n",
      "('tom forgot to do his homework.', '[start] tom a oubliã© de faire ses devoirs. [end]')\n",
      "(\"that's all tom did.\", \"[start] c'est tout ce que tom a fait. [end]\")\n",
      "('i felt left out.', '[start] je me sentis exclu. [end]')\n",
      "('i want to go over a few things with you.', '[start] je veux parcourir quelques trucs avec toi. [end]')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for _ in range(5):\n",
    "    print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7841407e-b517-434e-977b-cc8f8c9075a1",
   "metadata": {},
   "source": [
    "# Tokenization and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbc72681-636a-421d-8600-3f293016e1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in English: 25380\n",
      "Total tokens in French: 44866\n",
      "Maximum length of English sequence: 47\n",
      "Maximum length of French sequence: 56\n"
     ]
    }
   ],
   "source": [
    "eng_tokens, fre_tokens = set(), set()\n",
    "eng_maxlen, fre_maxlen = 0, 0\n",
    "\n",
    "for eng , fre in text_pairs:\n",
    "    eng_token, fre_token = eng.split(), fre.split()\n",
    "    eng_maxlen = max(eng_maxlen, len(eng_token))\n",
    "    fre_maxlen = max(fre_maxlen, len(fre_token))\n",
    "    eng_tokens.update(eng_token)\n",
    "    fre_tokens.update(fre_token)\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Total tokens in English: {len(eng_tokens)}\")\n",
    "print(f\"Total tokens in French: {len(fre_tokens)}\")\n",
    "print(f\"Maximum length of English sequence: {eng_maxlen}\")\n",
    "print(f\"Maximum length of French sequence: {fre_maxlen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f531a008-7fe1-4660-9cc9-316333d7e71b",
   "metadata": {},
   "source": [
    "# Data Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdde3754-d4cd-4dae-a18b-b52ef5426753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Serialize preprocessed data for future use\n",
    "with open(\"text_pairs.pickle\", 'wb') as fp:\n",
    "    pickle.dump(text_pairs, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b05bbca-95c6-4763-af36-dec2ebe7a989",
   "metadata": {},
   "source": [
    "# Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08d6130d-54c6-4cf1-aef1-d7ed9a1a6a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "\n",
    "with open(\"text_pairs.pickle\" , 'rb') as fp:\n",
    "    text_pairs = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2d2bd97-07f6-4bfd-8892-2e515477d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(text_pairs)\n",
    "\n",
    "n_val = int(.15*len(text_pairs))\n",
    "n_train = len(text_pairs) - 2*n_val\n",
    "train_pair = text_pairs[:n_train]\n",
    "test_pair = text_pairs[n_train:n_train+n_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9469847a-9e07-40b7-825e-6fbba0e9e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_en = 10000\n",
    "vocab_fr = 20000\n",
    "seq_length = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "255c42de-3788-407b-8839-478f2de6926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TextVectorization layers\n",
    "eng_vect = TextVectorization(\n",
    "    max_tokens=vocab_en,\n",
    "    standardize=None,\n",
    "    split='whitespace',\n",
    "    output_mode='int',\n",
    "    output_sequence_length=seq_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "158d4dd5-b916-4791-a7f4-f79575ecffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fre_vect = TextVectorization(\n",
    "    max_tokens=vocab_fr,\n",
    "    standardize=None,\n",
    "    split='whitespace',\n",
    "    output_mode='int',\n",
    "    output_sequence_length=seq_length + 1  # +1 for start token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d287dfc-1297-4067-868c-ef1b9d0a41fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt TextVectorization layers to training data\n",
    "train_eng = [pair[0] for pair in train_pair]\n",
    "train_fre = [pair[1] for pair in train_pair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43d893cb-f79d-4d3f-bf82-ab6001a60993",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vect.adapt(train_eng)\n",
    "fre_vect.adapt(train_fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed442ff6-0afc-4b28-bd0a-bbc266578e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize the vectorization layers and training/test data\n",
    "with open('vectorize.pickle', 'wb') as fp:\n",
    "    data = {'train': train_pair,\n",
    "            'test': test_pair,\n",
    "            'eng_vect': eng_vect.get_config(),\n",
    "            'fre_vect': fre_vect.get_config(),\n",
    "            'eng_weights': eng_vect.get_weights(),\n",
    "            'fre_weights': fre_vect.get_weights()\n",
    "            }\n",
    "    pickle.dump(data, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90bf74da-b508-4789-b6a7-282dd424d443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load serialized data\n",
    "with open(\"vectorize.pickle\", 'rb') as fp:\n",
    "    data = pickle.load(fp)\n",
    "\n",
    "# Retrieve train and test pairs\n",
    "train_pair = data['train']\n",
    "test_pair = data['test']\n",
    "\n",
    "# Reconstruct TextVectorization layers\n",
    "eng_vect = TextVectorization.from_config(data['eng_vect'])\n",
    "eng_vect.set_weights(data['eng_weights'])\n",
    "fre_vect = TextVectorization.from_config(data['fre_vect'])\n",
    "fre_vect.set_weights(data['fre_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8c4a134-1445-4e96-98b4-a90bc193c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to format dataset\n",
    "def format_dataset(eng, fre):\n",
    "    eng = eng_vect(eng)\n",
    "    fre = fre_vect(fre)\n",
    "    source = {'encode_inp': eng,\n",
    "              'decode_inp': fre[:, :-1]\n",
    "              }\n",
    "    target = fre[:, 1:]\n",
    "    return (source, target)\n",
    "\n",
    "# Define function to create dataset\n",
    "def make_dataset(pairs, batchsize=64):\n",
    "    eng_text, fre_text = zip(*pairs)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(eng_text), list(fre_text)))\n",
    "    return dataset.shuffle(2048).batch(batchsize).map(format_dataset).prefetch(16).cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c197680f-8878-4705-98a6-3c1f2d25b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow datasets for training and testing\n",
    "train_ds = make_dataset(train_pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a69de2c-2af1-4947-a57b-148c826a76af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = make_dataset(test_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe7df02-7fc5-4988-80a8-9f850324d34c",
   "metadata": {},
   "source": [
    "# Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f6b8207-494f-4536-a932-826ace34ee23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask: tf.Tensor(\n",
      "[[ True  True  True  True  True False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False]\n",
      " [ True  True  True False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False]], shape=(2, 25), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to generate positional encoding matrix\n",
    "def pos_enc_matrix(L, d, n=10000):\n",
    "    assert d % 2 == 0\n",
    "    d2 = d // 2\n",
    "\n",
    "    P = np.zeros((L, d))\n",
    "    k = np.arange(L).reshape(-1, 1)\n",
    "    i = np.arange(d2).reshape(1, -1)\n",
    "\n",
    "    denom = np.power(n, -i / d2)\n",
    "    args = k * denom\n",
    "\n",
    "    P[:, ::2] = np.sin(args)\n",
    "    P[:, 1::2] = np.cos(args)\n",
    "    return P\n",
    "\n",
    "# Custom Keras layer for positional embedding\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, seq_length, vocab_size, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.seq_length = seq_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.token_embeddings = tf.keras.layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim, mask_zero=True\n",
    "        )\n",
    "        matrix = pos_enc_matrix(seq_length, embed_dim)\n",
    "        self.positional_embedding = tf.constant(matrix, dtype=tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        return embedded_tokens + self.positional_embedding\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return self.token_embeddings.compute_mask(inputs, mask)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"seq_length\": self.seq_length,\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"embed_dim\": self.embed_dim\n",
    "        })\n",
    "        return config\n",
    "\n",
    "vocab_size = 10000\n",
    "seq_length = 25\n",
    "embed_dim = 512\n",
    "\n",
    "# Create a text vectorization layer\n",
    "text_vectorization = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=seq_length\n",
    ")\n",
    "\n",
    "# Simulate raw text data (replace with actual dataset)\n",
    "raw_text_data = tf.constant([\"This is a test sentence\", \"Another example sentence\"])\n",
    "\n",
    "# Adapt the vectorization layer to the dataset\n",
    "text_vectorization.adapt(raw_text_data)\n",
    "# Simulate a dataset (replace with real dataset)\n",
    "train_data = raw_text_data  # Replace with actual text dataset\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train_data)\n",
    "train_ds = train_ds.map(lambda x: {\"encode_inp\": text_vectorization(x), \"target\": x})\n",
    "train_ds = train_ds.batch(2)\n",
    "\n",
    "for inputs in train_ds.take(1):\n",
    "    embed_en = PositionalEmbedding(seq_length, vocab_size, embed_dim=embed_dim)\n",
    "    en_emb = embed_en(inputs[\"encode_inp\"])\n",
    "    mask = embed_en.compute_mask(inputs[\"encode_inp\"])\n",
    "    print(\"Mask:\", mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b253ca-09d5-4b7d-89b8-3de8dca5debd",
   "metadata": {},
   "source": [
    "# Self-Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3fbaee5-289a-4ea7-bdd8-eabea3e8b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def self_attention(input_shape, prefix='att', mask=False, **kwargs):\n",
    "    # Define inputs\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape, dtype='float32', name=f\"{prefix}_in1\")\n",
    "\n",
    "    # Multi-head attention layer\n",
    "    attention = tf.keras.layers.MultiHeadAttention(name=f\"{prefix}_att1\", **kwargs)\n",
    "    norm = tf.keras.layers.LayerNormalization(name=f'{prefix}_norm1')\n",
    "    add = tf.keras.layers.Add(name=f'{prefix}_add1')\n",
    "\n",
    "    # Apply attention mechanism\n",
    "    attout = attention(query=inputs, value=inputs, key=inputs, use_causal_mask=mask)\n",
    "\n",
    "    # Apply normalization and residual connection\n",
    "    output = norm(add([inputs, attout]))\n",
    "\n",
    "    # Create the model\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output, name=f\"{prefix}_att\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a0bab2-4649-4566-8239-4f1efb33e725",
   "metadata": {},
   "source": [
    "# Cross-Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34e53ca7-c716-4756-8c6b-2216d110bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_attention(input_shape, context_shape, prefix='att', **kwargs):\n",
    "    # Define inputs\n",
    "    context = tf.keras.layers.Input(shape=context_shape, dtype='float32', name=f\"{prefix}_ctx2\")\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape, dtype='float32', name=f'{prefix}_in2')\n",
    "\n",
    "    # Multi-head attention layer\n",
    "    attention = tf.keras.layers.MultiHeadAttention(name=f'{prefix}_att2', **kwargs)\n",
    "    norm = tf.keras.layers.LayerNormalization(name=f'{prefix}_norm2')\n",
    "    add = tf.keras.layers.Add(name=f'{prefix}_add2')\n",
    "\n",
    "    # Apply attention mechanism\n",
    "    attout = attention(query=inputs, key=context, value=context)\n",
    "\n",
    "    # Apply normalization and residual connection\n",
    "    output = norm(add([attout, inputs]))\n",
    "\n",
    "    # Create the model\n",
    "    model = tf.keras.Model(inputs=[context, inputs], outputs=output, name=f'{prefix}_crs_at')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a2f181-d123-4e00-8358-81423a849f50",
   "metadata": {},
   "source": [
    "# Feed-Forward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8db5d2f8-9d3d-499d-8a36-3dff8647b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(input_shape, model_dim, ff_dim, dropout=.1, prefix='ff'):\n",
    "    # Define inputs\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape, dtype='float32', name=f'{prefix}_in3')\n",
    "\n",
    "    # Dense layers\n",
    "    dense1 = tf.keras.layers.Dense(ff_dim, name=f'{prefix}_ff1', activation='relu')\n",
    "    dense2 = tf.keras.layers.Dense(model_dim, name=f'{prefix}_ff2')\n",
    "    drop = tf.keras.layers.Dropout(dropout, name=f'{prefix}_drop')\n",
    "    add = tf.keras.layers.Add(name=f\"{prefix}_add3\")\n",
    "\n",
    "    # Apply feed-forward transformation\n",
    "    ffout = drop(dense2(dense1(inputs)))\n",
    "\n",
    "    # Layer normalization and residual connection\n",
    "    norm = tf.keras.layers.LayerNormalization(name=f'{prefix}_norm3')\n",
    "    output = norm(add([inputs, ffout]))\n",
    "\n",
    "    # Create the model\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output, name=f'{prefix}_ff')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ffc3e-1448-46bf-ba42-88a9a7cf1a11",
   "metadata": {},
   "source": [
    "# Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54766083-903c-49c5-83dd-29ad06690c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def encoder(input_shape, key_dim, ff_dim, dropout=0.1, prefix='enc', **kwargs):\n",
    "    # Define a Sequential model for the encoder\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=input_shape, dtype='float32', name=f'{prefix}_in0'), # Input layer\n",
    "        self_attention(input_shape, prefix=prefix, key_dim=key_dim, mask=False, **kwargs), # Self-attention layer\n",
    "        feed_forward(input_shape, key_dim, ff_dim, dropout, prefix) # Feed-forward layer\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "55b6e79c-4ed3-41d5-a885-9c6c1f840ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "seq_length = 25\n",
    "key_dim = 128\n",
    "ff_dim = 512\n",
    "num_heads = 8\n",
    "\n",
    "model = encoder(input_shape = (seq_length,key_dim),key_dim = key_dim , ff_dim = ff_dim , num_heads = num_heads)\n",
    "\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78ccb98-429b-4eb9-8292-9a7fcb201225",
   "metadata": {},
   "source": [
    "# Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7da5791-962d-4d80-a13a-6c5c29db7674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(input_shape, key_dim, ff_dim, dropout=0.1, prefix='dec', **kwargs):\n",
    "    # Define inputs for decoder\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape, dtype='float32', name=f'{prefix}_in0')\n",
    "    context = tf.keras.layers.Input(shape=input_shape, dtype='float32', name=f'{prefix}_ctx0')\n",
    "    \n",
    "    # Self-attention and cross-attention layers\n",
    "    att_model = self_attention(input_shape, key_dim=key_dim, mask=True, prefix=prefix, **kwargs)\n",
    "    cross_model = cross_attention(input_shape, input_shape, key_dim=key_dim, prefix=prefix, **kwargs)\n",
    "    \n",
    "    # Feed-forward layer\n",
    "    ff_model = feed_forward(input_shape, key_dim, ff_dim, dropout, prefix)\n",
    "\n",
    "    # Connect layers\n",
    "    x = att_model(inputs)\n",
    "    x = cross_model([context, x])\n",
    "    output = ff_model(x)\n",
    "\n",
    "    # Define decoder model\n",
    "    model = tf.keras.Model(inputs=[inputs, context], outputs=output, name=prefix)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8462225d-e8ac-404e-97bd-d880704383f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "seq_length = 25\n",
    "key_dim = 128\n",
    "ff_dim = 512\n",
    "num_heads = 8\n",
    "\n",
    "model =decoder(input_shape = (seq_length,key_dim),key_dim = key_dim , ff_dim = ff_dim , num_heads = num_heads)\n",
    "\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a72e7-7e24-4c20-a16b-ca55136f2fcd",
   "metadata": {},
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "74a4893b-b87d-4722-95c9-901d50f9627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(num_layers, num_heads, seq_length, key_dim, ff_dim, vocab_size_en, vocab_size_fr, dropout=0.1, name='transformer'):\n",
    "    # Define encoder and decoder inputs\n",
    "    input_enc = tf.keras.layers.Input(shape=(seq_length,), dtype='int32', name='encode_inp')\n",
    "    input_dec = tf.keras.layers.Input(shape=(seq_length,), dtype='int32', name='decode_inp')\n",
    "\n",
    "\n",
    "    # Positional embeddings for encoder and decoder inputs\n",
    "    emb_enc = PositionalEmbedding(seq_length, vocab_size_en, key_dim, name='embed_enc')\n",
    "    emb_dec = PositionalEmbedding(seq_length, vocab_size_fr, key_dim, name='embed_dec')\n",
    "\n",
    "    # Create encoder and decoder layers\n",
    "    encoders = [encoder(input_shape=(seq_length, key_dim), key_dim=key_dim, ff_dim=ff_dim, dropout=dropout, prefix=f\"enc{i}\", num_heads=num_heads)\n",
    "                for i in range(num_layers)]\n",
    "    decoders = [decoder(input_shape=(seq_length, key_dim), key_dim=key_dim, ff_dim=ff_dim, dropout=dropout, prefix=f\"dec{i}\", num_heads=num_heads)\n",
    "                for i in range(num_layers)]\n",
    "\n",
    "    # Final dense layer\n",
    "    final = tf.keras.layers.Dense(vocab_size_fr, name='linear')\n",
    "\n",
    "    # Apply encoder and decoder layers to inputs\n",
    "    x1 = emb_enc(input_enc)\n",
    "    x2 = emb_dec(input_dec)\n",
    "    for layer in encoders:\n",
    "        x1 = layer(x1)\n",
    "    for layer in decoders:\n",
    "        x2 = layer([x2, x1])\n",
    "\n",
    "    # Generate output\n",
    "    output = final(x2)\n",
    "\n",
    "    try:\n",
    "        del output.keras_mask\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Define transformer model\n",
    "    model = tf.keras.Model(inputs=[input_enc, input_dec], outputs=output, name=name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a94cddba-51d6-464a-ba1b-5387da2c62ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gupta\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:939: UserWarning: Layer 'sequential_1' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gupta\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:939: UserWarning: Layer 'dec0' (of type Functional) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "seq_length = 25\n",
    "num_layers = 4\n",
    "num_heads = 8\n",
    "key_dim = 128\n",
    "ff_dim = 512\n",
    "dropout = .1\n",
    "vocab_size_en = 10000\n",
    "vocab_size_fr = 20000\n",
    "\n",
    "model = transformer(num_layers, num_heads,seq_length,key_dim,ff_dim,vocab_size_en,vocab_size_fr,dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3e58d69-8a38-4fe3-8db3-b90240c4ad1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encode_inp (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embed_enc                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ encode_inp[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encode_inp[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">659,712</span> │ embed_enc[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">659,712</span> │ sequential_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decode_inp (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">659,712</span> │ sequential_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embed_dec                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │ decode_inp[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">659,712</span> │ sequential_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decode_inp[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,187,456</span> │ embed_dec[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ sequential_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│                               │                           │                 │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,187,456</span> │ dec0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],                │\n",
       "│                               │                           │                 │ sequential_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,187,456</span> │ dec1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],                │\n",
       "│                               │                           │                 │ sequential_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,187,456</span> │ dec2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],                │\n",
       "│                               │                           │                 │ sequential_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ linear (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,580,000</span> │ dec3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                 │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encode_inp (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embed_enc                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │       \u001b[38;5;34m1,280,000\u001b[0m │ encode_inp[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ encode_inp[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m659,712\u001b[0m │ embed_enc[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_2 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m659,712\u001b[0m │ sequential_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decode_inp (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_3 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m659,712\u001b[0m │ sequential_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embed_dec                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │       \u001b[38;5;34m2,560,000\u001b[0m │ decode_inp[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_4 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m659,712\u001b[0m │ sequential_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_1 (\u001b[38;5;33mNotEqual\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ decode_inp[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec0 (\u001b[38;5;33mFunctional\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │       \u001b[38;5;34m1,187,456\u001b[0m │ embed_dec[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ sequential_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│                               │                           │                 │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec1 (\u001b[38;5;33mFunctional\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │       \u001b[38;5;34m1,187,456\u001b[0m │ dec0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],                │\n",
       "│                               │                           │                 │ sequential_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec2 (\u001b[38;5;33mFunctional\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │       \u001b[38;5;34m1,187,456\u001b[0m │ dec1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],                │\n",
       "│                               │                           │                 │ sequential_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec3 (\u001b[38;5;33mFunctional\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │       \u001b[38;5;34m1,187,456\u001b[0m │ dec2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],                │\n",
       "│                               │                           │                 │ sequential_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ linear (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m20000\u001b[0m)         │       \u001b[38;5;34m2,580,000\u001b[0m │ dec3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                 │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,808,672</span> (52.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,808,672\u001b[0m (52.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,808,672</span> (52.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,808,672\u001b[0m (52.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(loss = 'sparse_categorical_cross_entropy' , optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b38ff2-8dfb-4078-af88-7addb7a27a44",
   "metadata": {},
   "source": [
    "# Custom Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "25c0f672-afcd-4632-a6ef-4aed604cd20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, key_dim, warmup_steps=40000):\n",
    "    super().__init__()\n",
    "    self.key_dim = key_dim\n",
    "    self.warmup_steps = warmup_steps\n",
    "    self.d = tf.cast(self.key_dim, tf.float32)\n",
    "\n",
    "  def __call__(self, step):\n",
    "    # Convert step to float32\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    # Calculate learning rate schedule\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    return tf.math.rsqrt(self.d) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "  def get_config(self):\n",
    "    # Configuration for serialization\n",
    "    config ={\n",
    "      \"key_dim\": self.key_dim,\n",
    "      \"warmup_steps\": self.warmup_steps\n",
    "    }\n",
    "    return config\n",
    "\n",
    "# Define key dimension and create learning rate schedule\n",
    "key_dim = 128\n",
    "lr = CustomSchedule(key_dim)\n",
    "optimizer = tf.keras.optimizers.Adam(lr,beta_1 = .9 , beta_2 = .98 , epsilon = 1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d996baf-0182-486a-a69f-75b62a37307c",
   "metadata": {},
   "source": [
    "# Masked Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "315b723c-7412-4799-8c41-282f56cbde1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "  # Create mask for non-padded tokens\n",
    "  mask = label != 0\n",
    "\n",
    "  # Sparse categorical cross-entropy loss\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none'\n",
    "  )\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  # Apply mask to loss\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  # Compute average loss\n",
    "  loss = tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de799cb1-c9fa-42b0-9aa8-70155bad8620",
   "metadata": {},
   "source": [
    "# Masked Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "51ead666-10f7-4c1f-90f4-a5a23f3c89b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_accuracy(label, pred):\n",
    "  # Convert predictions to class labels\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "\n",
    "  # Calculate match between labels and predictions\n",
    "  match = label == pred\n",
    "\n",
    "  # Apply mask to match\n",
    "  mask = label != 0\n",
    "  match = match & mask\n",
    "\n",
    "  # Compute accuracy\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match) / tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f26ab8-1a2d-4140-b123-5e8720812702",
   "metadata": {},
   "source": [
    "# Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b1679d50-07bf-4cad-bf14-ed7073bcaa10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encode_inp (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embed_enc                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ encode_inp[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encode_inp[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">659,712</span> │ embed_enc[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">659,712</span> │ sequential_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decode_inp (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">659,712</span> │ sequential_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embed_dec                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │ decode_inp[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">659,712</span> │ sequential_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decode_inp[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,187,456</span> │ embed_dec[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ sequential_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│                               │                           │                 │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,187,456</span> │ dec0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],                │\n",
       "│                               │                           │                 │ sequential_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,187,456</span> │ dec1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],                │\n",
       "│                               │                           │                 │ sequential_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,187,456</span> │ dec2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],                │\n",
       "│                               │                           │                 │ sequential_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ linear (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,580,000</span> │ dec3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                 │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encode_inp (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embed_enc                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │       \u001b[38;5;34m1,280,000\u001b[0m │ encode_inp[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ encode_inp[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m659,712\u001b[0m │ embed_enc[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_2 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m659,712\u001b[0m │ sequential_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decode_inp (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_3 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m659,712\u001b[0m │ sequential_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embed_dec                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │       \u001b[38;5;34m2,560,000\u001b[0m │ decode_inp[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_4 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m659,712\u001b[0m │ sequential_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_1 (\u001b[38;5;33mNotEqual\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ decode_inp[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec0 (\u001b[38;5;33mFunctional\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │       \u001b[38;5;34m1,187,456\u001b[0m │ embed_dec[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ sequential_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│                               │                           │                 │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec1 (\u001b[38;5;33mFunctional\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │       \u001b[38;5;34m1,187,456\u001b[0m │ dec0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],                │\n",
       "│                               │                           │                 │ sequential_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec2 (\u001b[38;5;33mFunctional\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │       \u001b[38;5;34m1,187,456\u001b[0m │ dec1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],                │\n",
       "│                               │                           │                 │ sequential_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec3 (\u001b[38;5;33mFunctional\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │       \u001b[38;5;34m1,187,456\u001b[0m │ dec2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],                │\n",
       "│                               │                           │                 │ sequential_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ linear (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m20000\u001b[0m)         │       \u001b[38;5;34m2,580,000\u001b[0m │ dec3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                 │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,808,672</span> (52.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,808,672\u001b[0m (52.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,808,672</span> (52.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,808,672\u001b[0m (52.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the model with custom loss and metrics\n",
    "model.compile(loss=masked_loss, optimizer=optimizer, metrics=[mask_accuracy])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea83ad80-609f-49b8-acfb-2e248ced096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model  \n",
    "# this take lots of time\n",
    "history = model.fit(train_ds, epochs=20, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ff9571-c5d7-4be3-9e2e-a0945411df02",
   "metadata": {},
   "source": [
    "# Visualizing Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5836ad-8f96-4028-95cf-abe53b1d9321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualizing Training History\n",
    "fig, axs = plt.subplots(2, figsize=(6, 8), sharex=True)\n",
    "fig.suptitle('Training history')\n",
    "x = list(range(1, 21))  # Assuming 20 epochs\n",
    "axs[0].plot(x, history.history[\"loss\"], alpha=0.5, label=\"loss\")\n",
    "axs[0].plot(x, history.history[\"val_loss\"], alpha=0.5, label=\"val_loss\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend(loc=\"upper right\")\n",
    "axs[1].plot(x, history.history[\"masked_accuracy\"], alpha=0.5, label=\"mask_accuracy\")\n",
    "axs[1].plot(x, history.history[\"val_masked_accuracy\"], alpha=0.5, label=\"val_mask_accuracy\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6809fc8d-3ff7-4aaf-be98-faca84f2adb2",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fd1b0f7a-049f-4f43-a6f5-fd2589490621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    # Encode input sentence\n",
    "    enc_tokens = eng_vect([sentence])\n",
    "    lookup = list(fra_vect.get_vocabulary())\n",
    "    start_sent, end_sent = \"[start]\", \"[end]\"\n",
    "    output_sent = [start_sent]\n",
    "    for i in range(seq_length):\n",
    "        # Prepare decoder input\n",
    "        vector = fra_vect([\" \".join(output_sent)])\n",
    "        assert vector.shape == (1, seq_length + 1)\n",
    "        dec_tokens = vector[:, :-1]\n",
    "        assert dec_tokens.shape == (1, seq_length)\n",
    "        # Generate predictions\n",
    "        pred = model([enc_tokens, dec_tokens])\n",
    "        assert pred.shape == (1, seq_len, vocab_size_fr)\n",
    "        # Decode predicted token\n",
    "        word = lookup[np.argmax(pred[0, i, :])]\n",
    "        output_sent.append(word)\n",
    "        if word == end_sent:\n",
    "            break\n",
    "    return output_sent\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f587d5-2d68-4cb6-8484-312f9d2bc361",
   "metadata": {},
   "source": [
    "#### Test the model on sample test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b60d2ae-ebc7-4c23-bc1e-d49940a5b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count = 20\n",
    "for n in range(test_count):\n",
    "    eng_sent, fre_sent = random.choice(test_pairs)\n",
    "    translated = translate(eng_sent)\n",
    "    print(f\"Test case: {n}\")\n",
    "    print(f\"English sentence: {eng_sent}\")\n",
    "    print(f\"Translated sentence: {' '.join(translated)}\")\n",
    "    print(f\"French sentence: {fre_sent}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
